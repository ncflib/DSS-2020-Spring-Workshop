{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome\n",
    "\n",
    "For this workshop, we've set up a coding environment, with the necessary tools and data already preloaded. The interface that you're using is called Jupyter - which allows you to interact with code in your browser, though a format called a 'notebook'. In addition to being in the browser, Jupyter is pleasant because it's interactive, so you can interact with your code. The traditional way of running code involves writing a script and running the whole thing; the interactive approach used by Jupyter is better for data analysis, because you explore, tinker, and converse with your data.\n",
    "\n",
    "In this workshop, we're working in the browser, with Jupyter, Python and all the corresponding data installed on somebody else's computer, but it can be run on your own computers. While you're in the browser, keep in mind that your custom code is ephemeral - it won't stay saved for the long term.\n",
    "\n",
    "Welcome to a Jupyer notebook. Let's get comfortable with Jupyter before we dive into the fun bits. \n",
    "\n",
    "Jupyter is one of many execution environtments for Python and R. It allows you to run code in the cloud, without having to install dependencies and all the other stuff.\n",
    "\n",
    "\"Script-like\" execution means that you write down all the code in a file, and that entire file is run in order.\n",
    "\n",
    "\"Interpreter-like\" execution means that you type in commands one at a time. The session pauses after each, waiting for the next command. This is really similar to how the command line is run.\n",
    "\n",
    "Jupyter is a hybrid of both those things. Notebooks are composed of cells. Then the cells are executed (almost like mini scripts). This gives you the advantage of keeping the session alive so you don't have to repeat loading data, etc., and the advantage of being able to execute multiple lines of code at the same time. It's also really easy to iterate through problems in a Jupyter environment — try something, meet the error head on, resolve it, and continue, cell by cell.\n",
    "\n",
    "Jupyter is extremely powerful, but there are a few traps.\n",
    "\n",
    "Let's get comfortable with cells first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "Let's spend some time getting to know basic Python features. \n",
    "\n",
    "The print() function asks the computer to return a specific value (literally asking the computer to print what you want to the terminal). \n",
    "\n",
    "Click on the code chunk below and press SHIFT + ENTER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is a string. It's being returned to your console. Cool!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHIFT + ENTER executes a chunk of code. Try changing the text inside the quotation marks and press SHIFT + ENTER again. The output will be rendered in the subsequent chunk. Try it again in the following chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"John Smith\"\n",
    "age = \"27\"\n",
    "print(name + ', ' +  age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous chunk of code uses variables. Variables represent other things (in this case, the variable 'name' is a standin for \"John Smith\"; the variable 'age' is a standin for \"27\") The advantage of variables is that they can be assigned once and used multiple times throughout. They can also be reassigned.\n",
    "\n",
    "Run the final chunk below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = input('What is your name?: ')\n",
    "age = input('What is your age?: ')\n",
    "city = input('Where are you from?: ')\n",
    "\n",
    "print('Your name is: ' + name + '. You are ' + age + ' years old.' + ' You are from ' + city + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain what happened in the previous chunk? \n",
    "\n",
    "If you said that we are saving an input to a variable and then requesting the computer to return those variables, you got it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our tools\n",
    "\n",
    "Okay, so we now have a bit of an understanding about how Python works. While Python is a powerful language that can do many things, developers have made it easier for us to carry out specific tasks by creating 'libraries' that enable us to carry out tasks, like language processing, more easily. \n",
    "\n",
    "These libraries are additions to vanilla Python, so we have to import them. Press SHIFT + ENTER in the following chunk to import a few libraries that we'll be using throughout this lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk # natural language processing library\n",
    "import textify # text cleaning library\n",
    "nltk.download('punkt') # we'll save this for later.\n",
    "nltk.download('stopwords') # we'll save this for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now we have the tools that we need to carry out some basic text analysis and visualize it. By the way, the \"#\" above means that those lines are commented out — they're just there to explain what we're doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our data\n",
    "\n",
    "Now that we have our tools we can get to work, but first, we need to import our data. The following lines of code  will load *OUR SAMPLE* data into a variable called data. If you want to use your own data for this lesson, let us know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('dss-sample-data.txt','r').read() # change 'dss-sample-data.txt' to the name of your sample data.\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line of code assigns the sample data to the variable 'data'. This is cool, because we can now analyze our text without having to type 'open('dss-sample-data.txt', 'r')' every time we want to do something with it. That's one of the cool things about variables.\n",
    "\n",
    "Let's first review our text document to make sure it's what we want. In pseudo-code, the following chunk asks the computer to return the text of the data file. Then we save that output to a variable so that we can call on it whenver we want.\n",
    "\n",
    "\n",
    "Press SHIFT + ENTER in the following chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. It's displaying properly, which means that we have successfully loaded the file to the data variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "Our text is pretty clean (it was transcribed and annotated by hand, so it better be!) but before we work on it we need to do a few things. Notice how there are random characters, like \\n\\n (new line symbols)? These are all hidden characters that you don't see when you're typing, but that exist to format a document to your liking. We need to get rid of them, as well as a few other things:\n",
    "\n",
    "1) Remove capitalizations\n",
    "2) Remove punctuation\n",
    "3) Remove numbers\n",
    "4) Apply stopwords\n",
    "\n",
    "We'll do that by using one of the tools (libraries) we imported previously! Textify! There are a lot of different ways to do this work, and there are better (more thorough) ways to do it, but textify makes it really easy for us. Execute the chunk of code below by pressing SHIFT + ENTER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textify import TextCleaner # we import a particular function from the library, Textify\n",
    "textcleaner = TextCleaner() # \n",
    "textcleaner.text = text # Taking the text and cleaning it with the utility function\n",
    "cleantext = textcleaner.clean_text() # printing the first 1000 characters from the above.\n",
    "print(cleantext[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what happened? The Textify library manipulated your text. Name a few of the changes that you notice. \n",
    "\n",
    "Your text can definitely be more clean, but for now, this is good enough. Let's visualize word frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our clean text is ready to go (somewhat normalized). We need to split up this mass of prose into individual words, or tokens, and then count the number of times they appear. Let's do that next.\n",
    "\n",
    "Remember that NLTK library that we imported? Time to use it. NLTK stands for Natural Language Toolkit, and it's a library that has a bunch of tools for us to apply natural language proccessing. We're going to use some of the basic tools they provide. First, let's tokenize. Press SHIFT + ENTER on the next block of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into word tokens\n",
    "from nltk.tokenize import word_tokenize  # import a particular library and specific functions\n",
    "tokens = word_tokenize(cleantext) # setting the output of word_tokenize() to the variable tokens\n",
    "print(tokens[0:100]) # printing the first 100 tokenized words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! Ugly error. But Python is pretty good at explaining what's wrong. Can you fix this NameError? Go ahead and edit the chunk above it to make it work. \n",
    "\n",
    "Hint: The variable that's being printed is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. We have a list of words. Now we need to get rid of stop words. NLTK let's us do that, too. Click on the next cell and press SHIFT + ENTER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # import the stopwords \n",
    "stop_words = stopwords.words('english') # set the stopwords list in english to the variable stop_words\n",
    "print(stop_words) # let's see these stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! Above you see the list of stopwords that we will apply. \n",
    "\n",
    "Next, let's apply that stopwords list to our corpus. Press SHIFT + ENTER on the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in tokens if not w in stop_words] # Here we ask the program to add a word to the variable words so long as it's not a word in the stopwords list\n",
    "print(words[:100]) # let's print the first 100 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a second and explain what's happening in this line: \n",
    "* words = [w for w in tokens if not w in stop_words] \n",
    "\n",
    "We're asking the program to create a list of words, save it to the variable 'words', based on a particular condition. That condition is a combination of FOR/IF expressions. In English [w for w in tokens if not w in stop words] translates to: assign w(ord) in variable tokens if that w(ord) is not in the stop words list! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the list of words we want to visualize, we need to count them. The following chunk does that for us by using a FOR expression and an IF expression. Basically, we're asking the program to iterate through the words list and count the number of times a word appears in the text. The output is the word, followed by its frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = {} # a dictionary of words. A dictionary is a collection which is unordered, changeable and indexed. In Python dictionaries are written with curly brackets, and they have keys and values.\n",
    "for w in words:  # there's the for expression again — for each w(ord) in the words variable from above\n",
    "    if w not in wordfreq: # if the w(ord) is not in the dicitonary of words above\n",
    "        wordfreq[w] = 0  # add it\n",
    "    wordfreq[w] += 1 # add +1 to the count of how many times you've added it\n",
    "\n",
    "wordfreq   # let's see the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a WORD and the number of times the word appears in the text (Frequency), we can plot it! We will do this step by step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # let's grab some libraries that make our life a little easier!\n",
    "\n",
    "\n",
    "df = pd.Series(data=wordfreq).reset_index() # we create a variable called df (stands for dataframe, another word for a table), and we ask it to use the wordfreq variable as it's data\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the output of wordfreq with the output of display(df). If you're thinking that the dataframe is easier to read, you're right — because it's a table and we know how to read them (an index, rows, columns, done). But this one is missing some important information, like column headers that make sense. Let's change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Word', 'Count'] # Without this, we don't have column names in our dataframe.\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better. Now that we know what we're dealing with, let's sort this table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Count', ascending=False) # take the df and sort it (sort_values) by the Count column, from most to least.\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfuly sorted this table by the number of times a word appears, but it's showing all of the words (4763). Let's only look at the top 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.nlargest(30, ['Count'])  # change the '10' to whatever number you want to see more words.\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a sense of the most frequent words that are used, and we've organized it appropriately. Let's visualize them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(x='Word', y='Count', rot=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using matplotlib, a library for visualizing data, we can create a barchart for all of these frequencies. Change the rot=30 attribute if you want the words to appear at a different angle. Matplotlib is a great library, but it's not known for its looks. We can change the way graphs appear by running the following chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot') # this line asks matplotlib to use another style sheet from a popular R package, ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot all of this work again!\n",
    "\n",
    "df.plot.bar(x='Word', y='Count', rot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, what's exploratory text analysis without some wordclouds! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud # import the wordcloud library\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100, max_words=100, background_color=\"white\").generate(text) # play around with the values and see what happens\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
